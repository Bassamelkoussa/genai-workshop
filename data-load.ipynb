{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88eddbdd-94d5-44fa-b54f-844b67966d44",
   "metadata": {},
   "source": [
    "# Neo4j Generative AI - Data Loading\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/neo4j-product-examples/genai-workshop/blob/main/data-load.ipynb)\n",
    "\n",
    "This workshop will teach you to how to use Neo4j for Graph-Powered Retrieval-Augmented Generation (GraphRAG) to enhance GenAI and improve response quality for real-world applications.\n",
    "\n",
    "GenAI, despite its potential, faces challenges like hallucination and lack of domain knowledge. GraphRAG addresses these issues by combining vector search with knowledge graphs and data science techniques. This integration helps improve context, semantic understanding, and personalization, making Large Language Models (LLMs) more effective for critical applications.\n",
    "\n",
    "We walk through an example that uses real-world customer and product data from a fashion, style, and beauty retailer. We show how you can use a knowledge graph to ground an LLM, enabling it to build tailored marketing content personalized to each customer based on their interests and shared purchase histories. We use Retrieval-Augmented Generation (RAG) to accomplish this,  specifically leveraging not just vector search but also graph pattern matching and graph machine learning to provide more relevant personalized results to customers. We call this graph-powered RAG approach “GraphRAG” for short.\n",
    "\n",
    "This notebook walks through the first steps of the process, including:\n",
    "- Building the knowledge graph and generating text embeddings from scratch \n",
    "\n",
    "*If you would rather start from a database dump and skip data loading, please skip to [genai-workshop.ipynb](https://github.com/neo4j-product-examples/genai-workshop/blob/main/genai-workshop.ipynb)* \n",
    "\n",
    "\n",
    "\n",
    "Please also see the following companion notebooks to complete the workshop: \n",
    "\n",
    "- [genai-workshop.ipynb](https://github.com/neo4j-product-examples/genai-workshop/blob/main/genai-workshop.ipynb)\n",
    "    - Vector search \n",
    "    - Using graph patterns in Cypher to improve semantic search with context\n",
    "    - Further augmenting semantic search with knowledge graph inference & graph data science    \n",
    "    - Building the LLM chain and demo app for generating content \n",
    "    \n",
    "- [genai-example-app-only](https://github.com/neo4j-product-examples/genai-workshop/blob/main/genai-workshop-app-only.ipynb)\n",
    "    - Building the LLM chain and demo app for generating content \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a527357f-a5e8-42c9-8966-f37846097c1d",
   "metadata": {},
   "source": [
    "### Some Logics\n",
    "1. Run the pip install below to get the necessary dependencies.  this can take a while. Then run the following cell to import relevant libraries\n",
    "2. You will need a Neo4j database environment with the [graph data science library](https://neo4j.com/docs/graph-data-science/current/installation) installed e.g. \n",
    "    - [AuraDS](https://neo4j.com/docs/aura/aurads/) \n",
    "    - [Neo4j Desktop](https://neo4j.com/docs/browser-manual/current/deployment-modes/neo4j-desktop/) \n",
    "    - Your own server environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2481cc-cf56-45d3-aa5a-236c0dbc7255",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install sentence_transformers langchain langchain-openai langchain_community openai tiktoken python-dotenv gradio graphdatascience altair neo4j_tools\n",
    "%pip install \"vegafusion[embed]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad71e3b-ccb9-4f5d-931f-4959862b16df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from graphdatascience import GraphDataScience\n",
    "from neo4j_tools import gds_db_load, gds_utils\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.vectorstores.neo4j_vector import Neo4jVector\n",
    "from langchain.graphs import Neo4jGraph\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.schema.runnable import RunnableLambda\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7af80e-7146-4280-a75a-7bccf16a2611",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "pd.set_option('display.width', 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0418616e-c078-448d-83c5-ab907bf08236",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Setup Credentials and Environment Variables\n",
    "\n",
    "There are two things you need here.\n",
    "1. Start a blank graph data science neo4j sandbox [Neo4j Sandbox](https://sandbox.neo4j.com/). Get your URI and password and plug them in below.  Do not change the Neo4j username.\n",
    "2. Get your OpenAI API key.  You can use [this one](https://docs.google.com/document/d/19Lqjd0MqRs088KUVnd23ZrVU9G0OAg-53U72VrFwwms/edit) if you do not have one already.\n",
    "\n",
    "To make this easy, you can write the credentials and env variables directly into the below cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076f0ca5-c7bd-4d77-b0c8-26cc5ef7bdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neo4j\n",
    "NEO4J_URI = 'copy_paste_your_db_uri_here' #change this\n",
    "NEO4J_PASSWORD = 'terminologies-fire-planet' #change this\n",
    "NEO4J_USERNAME = 'neo4j'\n",
    "AURA_DS = True\n",
    "\n",
    "# AI\n",
    "LLM = 'gpt-4o'\n",
    "os.environ['OPENAI_API_KEY'] = 'sk-...' #change this\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f674b2d-da73-4d6d-be03-d259478f7cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can skip this cell if not using a ws.env file - alternative to above\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "if os.path.exists('ws.env'):\n",
    "    load_dotenv('ws.env', override=True)\n",
    "\n",
    "    # Neo4j\n",
    "    NEO4J_URI = os.getenv('NEO4J_URI')\n",
    "    NEO4J_USERNAME = os.getenv('NEO4J_USERNAME')\n",
    "    NEO4J_PASSWORD = os.getenv('NEO4J_PASSWORD')\n",
    "    AURA_DS = eval(os.getenv('AURA_DS').title())\n",
    "\n",
    "    # AI\n",
    "    LLM = 'gpt-4o'\n",
    "    OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9baad48-4875-4780-a168-e8eba6b95df5",
   "metadata": {},
   "source": [
    "## Knowledge Graph Building\n",
    "\n",
    "<img src=\"img/hm-banner.png\" alt=\"summary\" width=\"2000\"/>\n",
    "\n",
    "We begin by building our knowledge graph. This workshop will leverage the [H&M Personalized Fashion Recommendations Dataset](https://www.kaggle.com/competitions/h-and-m-personalized-fashion-recommendations/data), a sample of real customer purchase data that includes rich information around products including names, types, descriptions, department sections, etc.\n",
    "\n",
    "Below is the graph data model we will use:\n",
    "\n",
    "<img src=\"img/data-model.png\" alt=\"summary\" width=\"1000\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37effc05-88bb-4ee4-9cbe-548a15069649",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Connect to Neo4j\n",
    "\n",
    "We will use the [Graph Data Science Python Client](https://neo4j.com/docs/graph-data-science-client/current/) to connect to Neo4j. This client makes it convenient to display results, as we will see later.  Perhaps more importantly, it allows us to easily run [Graph Data Science](https://neo4j.com/docs/graph-data-science/current/introduction/) algorithms from Python.\n",
    "\n",
    "This client will only work if your Neo4j instance has Graph Data Science installed.  If not, you can still use the [Neo4j Python Driver](https://neo4j.com/docs/python-manual/current/) or use Langchain’s Neo4j Graph object that we will see later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbee8fc-9699-493e-b75e-2068dd208ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Neo4j URI and credentials according to our setup\n",
    "gds = GraphDataScience(\n",
    "    NEO4J_URI,\n",
    "    auth=(NEO4J_USERNAME, NEO4J_PASSWORD),\n",
    "    aura_ds=AURA_DS)\n",
    "\n",
    "# Necessary if you enabled Arrow on the db - this is true for AuraDS\n",
    "gds.set_database(\"neo4j\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2df684-9d7f-44ab-ae05-7a42b91a204e",
   "metadata": {},
   "source": [
    "Test your connection by running the below.  It should output your system information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a02d2d-f894-4e7b-9910-20dcc54cae5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gds.debug.sysInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a831e09-3b57-43a7-b79d-e2c9845334f6",
   "metadata": {},
   "source": [
    "### Get Source Data\n",
    "This workshop will leverage the [H&M Personalized Fashion Recommendations Dataset](https://www.kaggle.com/competitions/h-and-m-personalized-fashion-recommendations/data), a sample of real customer purchase data that includes rich information around products including names, types, descriptions, department sections, etc.\n",
    "\n",
    "*Bonus!*\n",
    "The data we use is a slightly sampled and preformatted version of the kaggle data. If you are interested in what we did, you can find the details [here](https://github.com/neo4j-product-examples/genai-workshop/blob/main/data-prep.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd8856c-6132-427e-8add-f344882954b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# get source data - it has been pre-formatted. If you would like to re-generate from source on Kaggle, see the data-prep.ipynb notebook\n",
    "department_df = pd.read_csv('https://storage.googleapis.com/neo4j-workshop-data/genai-hm/department.csv')\n",
    "product_df = pd.read_csv('https://storage.googleapis.com/neo4j-workshop-data/genai-hm/product.csv')\n",
    "article_df = pd.read_csv('https://storage.googleapis.com/neo4j-workshop-data/genai-hm/article.csv')\n",
    "customer_df = pd.read_csv('https://storage.googleapis.com/neo4j-workshop-data/genai-hm/customer.csv')\n",
    "transaction_df = pd.read_csv('https://storage.googleapis.com/neo4j-workshop-data/genai-hm/transaction.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f4341e-334d-4764-aca6-8178e69c9f30",
   "metadata": {},
   "source": [
    "### Create Constraints\n",
    "\n",
    "Before loading data into Neo4j, it is usually best practice to create Key or Uniqueness constraints for nodes. These [constraints](https://neo4j.com/docs/cypher-manual/current/constraints/) act as an index with some validation on unique id properties and thus make `MATCH` statements run significantly faster. Not doing this can result in a VERY slow ingest, so this is a critical step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e37adb5-1ad3-4b71-adfa-24b5d2bf22b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create constraints - one uniqueness constraint for each node label\n",
    "gds.run_cypher('CREATE CONSTRAINT unique_department_no IF NOT EXISTS FOR (n:Department) REQUIRE n.departmentNo IS UNIQUE')\n",
    "gds.run_cypher('CREATE CONSTRAINT unique_product_code IF NOT EXISTS FOR (n:Product) REQUIRE n.productCode IS UNIQUE')\n",
    "gds.run_cypher('CREATE CONSTRAINT unique_article_id IF NOT EXISTS FOR (n:Article) REQUIRE n.articleId IS UNIQUE')\n",
    "gds.run_cypher('CREATE CONSTRAINT unique_customer_id IF NOT EXISTS FOR (n:Customer) REQUIRE n.customerId IS UNIQUE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f331d91-f8e6-45bb-b5b2-2f10d2aafa66",
   "metadata": {},
   "source": [
    "### Loading Data with Helper Functions\n",
    "\n",
    "Since we normalized our data beforehand, we can load each node and relationship type separately in batches.\n",
    "The Node and Relationship query patterns will follow the same template for different types.  The functions in `gds_db_load` simply automatically construct the queries and handle the batching.  They will print the queries they are using while loading so you can see the patterns.\n",
    "\n",
    "Cypher for Loading Nodes follows a MATCH-MERGE pattern, while Cypher for loading relationships follows a MATCH-MATCH-MERGE pattern.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7672d6-89bd-493c-b6b5-b3b0494141da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j_tools import gds_db_load\n",
    "\n",
    "%%time\n",
    "# load nodes\n",
    "gds_db_load.load_nodes(gds, department_df, 'departmentNo', 'Department')\n",
    "gds_db_load.load_nodes(gds, article_df.drop(columns=['productCode', 'departmentNo']), 'articleId', 'Article')\n",
    "gds_db_load.load_nodes(gds, product_df, 'productCode', 'Product')\n",
    "gds_db_load.load_nodes(gds, customer_df, 'customerId', 'Customer')\n",
    "\n",
    "# load relationships\n",
    "gds_db_load.load_rels(gds, article_df[['articleId', 'departmentNo']], source_target_labels=('Article', 'Department'),\n",
    "                      source_node_key='articleId', target_node_key='departmentNo',\n",
    "                      rel_type='FROM_DEPARTMENT')\n",
    "gds_db_load.load_rels(gds, article_df[['articleId', 'productCode']], source_target_labels=('Article', 'Product'),\n",
    "                      source_node_key='articleId',target_node_key='productCode',\n",
    "                      rel_type='VARIANT_OF')\n",
    "gds_db_load.load_rels(gds, transaction_df, source_target_labels=('Customer', 'Article'),\n",
    "                      source_node_key='customerId', target_node_key='articleId', rel_key='txId',\n",
    "                      rel_type='PURCHASED')\n",
    "\n",
    "# convert transaction dates\n",
    "gds.run_cypher('''\n",
    "MATCH (:Customer)-[r:PURCHASED]->()\n",
    "SET r.tDat = date(r.tDat)\n",
    "''')\n",
    "\n",
    "# convert NaN product descriptions\n",
    "gds.run_cypher('''\n",
    "MATCH (n:Product) WHERE valueType(n.detailDesc) <> \"STRING NOT NULL\"\n",
    "SET n.detailDesc = \"\"\n",
    "RETURN n\n",
    "''')\n",
    "\n",
    "# create combined text property. This will help simplify later with semantic search and RAG\n",
    "gds.run_cypher(\"\"\"\n",
    "    MATCH(p:Product)\n",
    "    SET p.text = 'Product-- ' +\n",
    "        'Name: ' + p.prodName + ' || ' +\n",
    "        'Type: ' + p.productTypeName + ' || ' +\n",
    "        'Group: ' + p.productGroupName + ' || ' +\n",
    "        'Garment Type: ' + p.garmentGroupName + ' || ' +\n",
    "        'Description: ' + p.detailDesc\n",
    "    RETURN count(p) AS propertySetCount\n",
    "    \"\"\")\n",
    "\n",
    "# write dummy urls to illustrate sourcing in future retrieval\n",
    "gds.run_cypher(\"\"\"\n",
    "MATCH(p:Product)\n",
    "SET p.url = 'https://representative-domain/product/' + p.productCode\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d49a5c6-9732-461e-8052-ac3751ff3498",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Creating Text Embeddings & Vector Index\n",
    "\n",
    "Now the data has been loaded, we need to generate text embeddings on our product nodes to support Vector Search\n",
    "\n",
    "Neo4j has native integrations with popular embedding APIs (OpenAI, Vertex AI, Amazon Bedrock, Azure OpenAI) making it possible to generate embeddings with a single Cypher query using `genai.vector.*` operations*.\n",
    "\n",
    "The below query embeds the Product text property with OpenAI `text-embedding-ada-002` in batches.  Specifically it\n",
    "1. Matches every Product that has a detailed description\n",
    "2. Uses the `collect` aggregation function to batch products into a set number of partitions\n",
    "3. Encodes the text property in batches using OpenAI `text-embedding-ada-002`\n",
    "4. Sets the embedding as a vector property using `db.create.setNodeVectorProperty`. This special function is used to set the properties as floats rather than double precision, which requires more space.  This becomes important as these embedding vectors tend to be long, and the size can add up quickly.\n",
    "\n",
    "*NOTE: `genai.vector.*` operations are not available in Neo4j Community Edition.  For Neo4j Community Edition you will need to generate embeddings externally and ingest them into Neo4j."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438cd7dc-b01c-48e2-b8d7-fef2bcf91aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate embeddings\n",
    "\n",
    "gds.run_cypher('''\n",
    "MATCH (n:Product) WHERE size(n.detailDesc) <> 0\n",
    "WITH collect(n) AS nodes, toInteger(rand()*$numberOfBatches) AS partition\n",
    "CALL {\n",
    "    WITH nodes\n",
    "    CALL genai.vector.encodeBatch([node IN nodes| node.text], \"OpenAI\", { token: $token})\n",
    "    YIELD index, vector\n",
    "    CALL db.create.setNodeVectorProperty(nodes[index], \"textEmbedding\", vector)\n",
    "} IN TRANSACTIONS OF 1 ROW''', params={'token':OPENAI_API_KEY, 'numberOfBatches':100})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b868b5f5-425a-4851-9351-36907909327f",
   "metadata": {},
   "source": [
    "After generating embeddings we will create a vector index for them. The Neo4j Vector Index enables efficient Approximate Nearest Neighbor (ANN) search with vectors. It uses the Hierarchical Navigable Small World (HNSW) algorithm.\n",
    "\n",
    "The below cell will create the index, then, with a separate query, await for the index to come online, meaning it is ready to be used in vector search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e4ccf2-65c8-468b-90ab-0bc489eb1e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create vector index\n",
    "\n",
    "embedding_dimension = 1536 #default for OpenAI text-embedding-ada-002\n",
    "\n",
    "gds.run_cypher('''\n",
    "CREATE VECTOR INDEX product_text_embeddings IF NOT EXISTS FOR (n:Product) ON (n.textEmbedding)\n",
    "OPTIONS {indexConfig: {\n",
    " `vector.dimensions`: toInteger($dimension),\n",
    " `vector.similarity_function`: 'cosine'\n",
    "}}''', params={'dimension': embedding_dimension})\n",
    "\n",
    "#wait for index to come online\n",
    "gds.run_cypher('CALL db.awaitIndex(\"product_text_embeddings\", 300)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ba071f-a3d4-4959-8236-e4d39cec0c19",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "Try out a vector search with your newly made vector index, and learn how to enhance that search with graphs and graph data science! [genai-workshop.ipynb](https://github.com/neo4j-product-examples/genai-workshop/blob/main/genai-workshop.ipynb)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
